{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from nn_model import *\n",
    "from nn_dataset import GeneDataset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['gene_id', 'transcript_pos'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = df.transcript_id.unique().tolist()\n",
    "train_genes_count = int(len(all_genes)*0.8)\n",
    "train_genes = all_genes[:train_genes_count]\n",
    "val_genes = all_genes[train_genes_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4266, 1067)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_genes), len(val_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.transcript_id.isin(train_genes)]\n",
    "val_df = df[df.transcript_id.isin(val_genes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['transcript_id', 'nucleo_seq', 'transcript_position', 'label'])\n",
    "y_train = train_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "for_scaler = df.drop(columns=['transcript_id', 'nucleo_seq', 'transcript_position', 'label'])\n",
    "scaler.fit(for_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ClassificationNN()\n",
    "clf = clf.float()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(clf.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "strtfdKFold = StratifiedKFold(n_splits=5)\n",
    "kfold = strtfdKFold.split(X_train, y_train)\n",
    "accuracy = []\n",
    "auc_roc = []\n",
    "pr_roc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, final loss: 5985.104\n",
      "Epoch: 1, final loss: 5967.990\n",
      "Epoch: 2, final loss: 5965.389\n",
      "Finish training\n",
      "Fold 1 | Accuracy: 0.6636626340794436 | AUC ROC: 0.727265182004766 | PR ROC 0.1011346905645211\n",
      "Epoch: 0, final loss: 5921.627\n",
      "Epoch: 1, final loss: 5921.762\n",
      "Epoch: 2, final loss: 5920.376\n",
      "Finish training\n",
      "Fold 2 | Accuracy: 0.648266065830721 | AUC ROC: 0.7052192032371926 | PR ROC 0.09644445661549494\n",
      "Epoch: 0, final loss: 5948.629\n",
      "Epoch: 1, final loss: 5948.370\n",
      "Epoch: 2, final loss: 5948.354\n",
      "Finish training\n",
      "Fold 3 | Accuracy: 0.6413597178683386 | AUC ROC: 0.721695126595331 | PR ROC 0.10330524849060814\n",
      "Epoch: 0, final loss: 5955.149\n",
      "Epoch: 1, final loss: 5956.887\n",
      "Epoch: 2, final loss: 5955.924\n",
      "Finish training\n",
      "Fold 4 | Accuracy: 0.6557112068965517 | AUC ROC: 0.723866003082891 | PR ROC 0.10156738417988977\n",
      "Epoch: 0, final loss: 5931.233\n",
      "Epoch: 1, final loss: 5931.881\n",
      "Epoch: 2, final loss: 5931.574\n",
      "Finish training\n",
      "Fold 5 | Accuracy: 0.6487558777429467 | AUC ROC: 0.7139447011774811 | PR ROC 0.09361120684335912\n",
      "Cross Val Accuracy: 0.6515511004836003 | AUC ROC: 0.7183980432195323 | PR ROC: 0.0992125973387746\n"
     ]
    }
   ],
   "source": [
    "for k, (train, test) in enumerate(kfold):\n",
    "    curr_X_train = X_train.iloc[train, :]\n",
    "    curr_y_train = y_train.iloc[train]\n",
    "\n",
    "    balanced_X_train, balanced_y_train = oversample.fit_resample(curr_X_train, curr_y_train)\n",
    "    balanced_X_train = scaler.transform(balanced_X_train)\n",
    "    train_dataset = GeneDataset(balanced_X_train, balanced_y_train)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    train_loop(train_dataloader, optimizer, criterion, clf, epochs=3)\n",
    "\n",
    "    curr_X_test = X_train.iloc[test, :]\n",
    "    curr_X_test = scaler.transform(curr_X_test)\n",
    "    curr_y_test = y_train.iloc[test]\n",
    "    test_dataset = GeneDataset(curr_X_test, curr_y_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    preds, probas, labels = eval_loop(test_dataloader, clf)\n",
    "    \n",
    "    auc_score = roc_auc_score(labels, probas)\n",
    "    ap = average_precision_score(labels, probas)\n",
    "\n",
    "    acc_score = accuracy_score(labels, preds)\n",
    "    auc_score = roc_auc_score(labels, probas)\n",
    "    pr_score = average_precision_score(labels, probas)\n",
    "\n",
    "    accuracy.append(acc_score)\n",
    "    auc_roc.append(auc_score)\n",
    "    pr_roc.append(pr_score)\n",
    "\n",
    "    print(f\"Fold {k+1} | Accuracy: {acc_score} | AUC ROC: {auc_score} | PR ROC {pr_score} || label 0: {len(balanced_y_train[balanced_y_train==0])}, label 1: {len(balanced_y_train[balanced_y_train==1])}\")\n",
    "\n",
    "print(f\"Cross Val Accuracy: {np.mean(accuracy)} | AUC ROC: {np.mean(auc_roc)} | PR ROC: {np.mean(pr_roc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df.drop(columns=['transcript_id', 'nucleo_seq', 'transcript_position', 'label'])\n",
    "y_val = val_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = GeneDataset(X_val, y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "val_preds, val_proba, val_labels = eval_loop(val_dataloader, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6416966138583793\n",
      "AUC-ROC: 0.7093601452664723\n",
      "PR-ROC: 0.09361120684335912\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(val_labels, val_preds)\n",
    "auc_score = roc_auc_score(val_labels, val_proba)\n",
    "pr_score = average_precision_score(val_labels, val_preds)\n",
    "\n",
    "print(\"Accuracy:\", acc_score)\n",
    "print(\"AUC-ROC:\", auc_score)\n",
    "print(\"PR-ROC:\", ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_dataset import GeneDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = GeneDataset(X_train, y_train)\n",
    "test = GeneDataset(X_test, y_test)\n",
    "val = GeneDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ClassificationNN()\n",
    "clf = clf.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(clf.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch: 1000, loss: 186.017\n",
      "Epoch: 1, batch: 2000, loss: 351.833\n",
      "Epoch: 1, batch: 3000, loss: 523.749\n",
      "Epoch: 1, batch: 4000, loss: 699.231\n",
      "Epoch: 1, batch: 5000, loss: 863.191\n",
      "Epoch: 1, batch: 6000, loss: 1033.188\n",
      "Epoch: 2, batch: 1000, loss: 167.041\n",
      "Epoch: 2, batch: 2000, loss: 331.576\n",
      "Epoch: 2, batch: 3000, loss: 499.482\n",
      "Epoch: 2, batch: 4000, loss: 671.408\n",
      "Epoch: 2, batch: 5000, loss: 844.963\n",
      "Epoch: 2, batch: 6000, loss: 1015.327\n",
      "Epoch: 3, batch: 1000, loss: 170.410\n",
      "Epoch: 3, batch: 2000, loss: 342.344\n",
      "Epoch: 3, batch: 3000, loss: 506.097\n",
      "Epoch: 3, batch: 4000, loss: 675.651\n",
      "Epoch: 3, batch: 5000, loss: 841.802\n",
      "Epoch: 3, batch: 6000, loss: 1012.435\n",
      "Epoch: 4, batch: 1000, loss: 165.142\n",
      "Epoch: 4, batch: 2000, loss: 332.557\n",
      "Epoch: 4, batch: 3000, loss: 503.062\n",
      "Epoch: 4, batch: 4000, loss: 675.893\n",
      "Epoch: 4, batch: 5000, loss: 841.435\n",
      "Epoch: 4, batch: 6000, loss: 1014.391\n",
      "Epoch: 5, batch: 1000, loss: 171.448\n",
      "Epoch: 5, batch: 2000, loss: 339.938\n",
      "Epoch: 5, batch: 3000, loss: 506.230\n",
      "Epoch: 5, batch: 4000, loss: 676.869\n",
      "Epoch: 5, batch: 5000, loss: 855.242\n",
      "Epoch: 5, batch: 6000, loss: 1020.800\n",
      "Epoch: 6, batch: 1000, loss: 169.822\n",
      "Epoch: 6, batch: 2000, loss: 338.786\n",
      "Epoch: 6, batch: 3000, loss: 515.050\n",
      "Epoch: 6, batch: 4000, loss: 680.250\n",
      "Epoch: 6, batch: 5000, loss: 853.219\n",
      "Epoch: 6, batch: 6000, loss: 1009.971\n",
      "Epoch: 7, batch: 1000, loss: 165.777\n",
      "Epoch: 7, batch: 2000, loss: 339.651\n",
      "Epoch: 7, batch: 3000, loss: 506.545\n",
      "Epoch: 7, batch: 4000, loss: 675.539\n",
      "Epoch: 7, batch: 5000, loss: 843.686\n",
      "Epoch: 7, batch: 6000, loss: 1011.663\n",
      "Epoch: 8, batch: 1000, loss: 173.956\n",
      "Epoch: 8, batch: 2000, loss: 336.053\n",
      "Epoch: 8, batch: 3000, loss: 507.261\n",
      "Epoch: 8, batch: 4000, loss: 673.542\n",
      "Epoch: 8, batch: 5000, loss: 836.243\n",
      "Epoch: 8, batch: 6000, loss: 1007.371\n",
      "Epoch: 9, batch: 1000, loss: 167.102\n",
      "Epoch: 9, batch: 2000, loss: 339.312\n",
      "Epoch: 9, batch: 3000, loss: 510.054\n",
      "Epoch: 9, batch: 4000, loss: 684.792\n",
      "Epoch: 9, batch: 5000, loss: 846.620\n",
      "Epoch: 9, batch: 6000, loss: 1017.847\n",
      "Epoch: 10, batch: 1000, loss: 166.995\n",
      "Epoch: 10, batch: 2000, loss: 340.257\n",
      "Epoch: 10, batch: 3000, loss: 509.586\n",
      "Epoch: 10, batch: 4000, loss: 679.173\n",
      "Epoch: 10, batch: 5000, loss: 846.257\n",
      "Epoch: 10, batch: 6000, loss: 1014.284\n",
      "Finish training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs (data is in a list of [X_train, y_train])\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels[:, None].float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = clf(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print verbose\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            print(f\"Epoch: {epoch+1}, batch: {i + 1:4d}, loss: {running_loss:.3f}\")\n",
    "\n",
    "print('Finish training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.eval()\n",
    "preds = []\n",
    "probas = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        x_test, y_test = data\n",
    "        x_test = x_test.float()\n",
    "\n",
    "        output = clf(x_test)\n",
    "        y_test = torch.flatten(y_test).tolist()\n",
    "        proba = torch.flatten(output).tolist()\n",
    "        pred = list(map(lambda x: 1 if x >= 0.5 else 0, proba))\n",
    "        preds += pred\n",
    "        probas += proba\n",
    "        labels += y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12177, 12177, 12177, 12177)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), len(probas), len(labels), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(data={'labels': labels,\n",
    "                                  'preds': preds,\n",
    "                                  'probas': probas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>probas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12177 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  preds    probas\n",
       "0           0      0  0.027629\n",
       "1           1      0  0.087624\n",
       "2           0      0  0.062826\n",
       "3           1      0  0.092178\n",
       "4           0      0  0.061673\n",
       "...       ...    ...       ...\n",
       "12172       0      0  0.028079\n",
       "12173       0      0  0.022819\n",
       "12174       0      0  0.018578\n",
       "12175       0      0  0.020540\n",
       "12176       0      0  0.092598\n",
       "\n",
       "[12177 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9462921901946292\n",
      "AUC-ROC: 0.6734661245253146\n",
      "PR-ROC: 0.11185075734590805\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(labels, probas)\n",
    "ap = average_precision_score(labels, probas)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(labels, preds))\n",
    "print(\"AUC-ROC:\", auc_score)\n",
    "print(\"PR-ROC:\", ap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa4266",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
